{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Date    : May-19-23 18:25\n",
    "# @Author  : Kan HUANG (kan.huang@connect.ust.hk)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_codes = np.asarray([[0., 1., 0., 1., 1.],\n",
    "               [0., 1., 1., 0., 1.],\n",
    "               [0., 1., 1., 1., 0.],\n",
    "               [1., 0., 0., 1., 1.],\n",
    "               [1., 0., 1., 0., 1.],\n",
    "               [1., 0., 1., 1., 0.],\n",
    "               [1., 1., 0., 0., 1.],\n",
    "               [1., 1., 0., 1., 0.],\n",
    "               [1., 1., 1., 0., 0.],\n",
    "               [0., 0., 1., 1., 1.],\n",
    "               [0., 1., 0., 1., 1.],\n",
    "               [0., 1., 1., 0., 1.],\n",
    "               [0., 1., 1., 1., 0.],\n",
    "               [1., 0., 0., 1., 1.],\n",
    "               [1., 0., 1., 0., 1.],\n",
    "               [1., 0., 1., 1., 0.]])\n",
    "target_codes = torch.from_numpy(target_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0046, 0.3287, 0.0013, 0.3772, 0.2881],\n",
       "        [0.0612, 0.3862, 0.2267, 0.0439, 0.2819],\n",
       "        [0.1301, 0.3126, 0.2980, 0.2385, 0.0208],\n",
       "        [0.3698, 0.0012, 0.0021, 0.4085, 0.2185],\n",
       "        [0.2148, 0.0037, 0.4546, 0.0037, 0.3231],\n",
       "        [0.2763, 0.0023, 0.3639, 0.3511, 0.0065],\n",
       "        [0.2900, 0.4032, 0.0109, 0.0017, 0.2943],\n",
       "        [0.3387, 0.2795, 0.0483, 0.3159, 0.0176],\n",
       "        [0.2981, 0.2507, 0.3761, 0.0488, 0.0264],\n",
       "        [0.0632, 0.0134, 0.3351, 0.3090, 0.2793],\n",
       "        [0.0022, 0.3886, 0.0013, 0.3287, 0.2791],\n",
       "        [0.0006, 0.2940, 0.4479, 0.0021, 0.2553],\n",
       "        [0.0053, 0.2553, 0.4061, 0.3255, 0.0079],\n",
       "        [0.3753, 0.0049, 0.0059, 0.3937, 0.2201],\n",
       "        [0.2797, 0.0232, 0.3793, 0.0259, 0.2918],\n",
       "        [0.2456, 0.0021, 0.3366, 0.4079, 0.0077]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16 x 5\n",
    "output = np.asarray([[-2.5099,  1.7667, -3.7351,  1.9043,  1.6348],\n",
    "        [-1.0646,  0.7772,  0.2445, -1.3976,  0.4623],\n",
    "        [-0.3707,  0.5058,  0.4578,  0.2354, -2.2048],\n",
    "        [ 2.1191, -3.5932, -3.0759,  2.2187,  1.5929],\n",
    "        [ 1.1155, -2.9434,  1.8652, -2.9491,  1.5238],\n",
    "        [ 1.4766, -3.3255,  1.7521,  1.7163, -2.2792],\n",
    "        [ 1.6706,  2.0003, -1.6131, -3.4864,  1.6853],\n",
    "        [ 0.7880,  0.5957, -1.1589,  0.7183, -2.1697],\n",
    "        [ 0.8532,  0.6800,  1.0857, -0.9564, -1.5706],\n",
    "        [-1.0329, -2.5878,  0.6344,  0.5535,  0.4525],\n",
    "        [-3.1936,  1.9788, -3.6889,  1.8114,  1.6479],\n",
    "        [-4.2443,  1.9574,  2.3783, -2.9731,  1.8163],\n",
    "        [-2.8714,  1.0121,  1.4761,  1.2548, -2.4620],\n",
    "        [ 1.5615, -2.7669, -2.5947,  1.6095,  1.0280],\n",
    "        [ 0.6863, -1.8052,  0.9909, -1.6921,  0.7287],\n",
    "        [ 1.3614, -3.3797,  1.6767,  1.8689, -2.1003]])\n",
    "output = torch.from_numpy(output)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "output_softmax = F.softmax(output, dim=1)\n",
    "output_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_softmax = torch.as_tensor((output_softmax - 0.5) > 0, dtype=torch.int32)\n",
    "result_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [6],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [7],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "distances = torch.zeros(len(output), len(target_codes))\n",
    "\n",
    "for i, _output in enumerate(output):\n",
    "    for j, target_code in enumerate(target_codes):\n",
    "        distances[i][j] = F.l1_loss(_output, target_code)\n",
    "pred = distances.argmax(dim=1, keepdim=True)\n",
    "print(pred)\n",
    "# correct += pred.eq(target.view_as(pred)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1, 4, 1, 0, 5, 2])\n",
    "labels = labels.unsqueeze(0)\n",
    "target = torch.zeros(labels.size(0), 15).scatter_(1, labels, 1.)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.Sigmoid()\n",
    "loss_fn = nn.BCELoss()\n",
    "input = torch.randn(3, 8, requires_grad=True)\n",
    "target = torch.empty(3, 8).random_(2)\n",
    "output = m(input)\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lenet import LeNet5\n",
    "\n",
    "output_dir = \"../output/ECOC-LeNet-5_MNIST_sgd_20230520-020335\"\n",
    "with open(f\"{output_dir}/config.json\") as f:\n",
    "   args = json.load(f)\n",
    "use_cuda = not args[\"no_cuda\"] and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = LeNet5(padding=2, output_dim=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kanhuang/Library/CloudStorage/OneDrive-HKUSTConnect/Codes/DeepLearning/Mathematics/ECOC/pytorch/predict.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kanhuang/Library/CloudStorage/OneDrive-HKUSTConnect/Codes/DeepLearning/Mathematics/ECOC/pytorch/predict.ipynb#ch0000009?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/ECOC-LeNet-5.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=786'>787</a>\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=787'>788</a>\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=788'>789</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=789'>790</a>\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=790'>791</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1128'>1129</a>\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1129'>1130</a>\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1130'>1131</a>\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1132'>1133</a>\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1134'>1135</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1098'>1099</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1099'>1100</a>\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1100'>1101</a>\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1102'>1103</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1078'>1079</a>\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39muntyped()\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1079'>1080</a>\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1080'>1081</a>\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1081'>1082</a>\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1082'>1083</a>\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=1083'>1084</a>\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=212'>213</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=213'>214</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=214'>215</a>\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=215'>216</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=216'>217</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=179'>180</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=180'>181</a>\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=181'>182</a>\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=182'>183</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=183'>184</a>\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=162'>163</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=164'>165</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=165'>166</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=166'>167</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=167'>168</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=168'>169</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=169'>170</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=170'>171</a>\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    <a href='file:///opt/miniconda3/envs/torch/lib/python3.8/site-packages/torch/serialization.py?line=171'>172</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{output_dir}/ECOC-LeNet-5.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize MNIST input.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "kwargs = {'batch_size': args[\"batch_size\"]}\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(args[\"seed\"])\n",
    "    kwargs.update({'num_workers': 1,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True},\n",
    "                    )\n",
    "print(\"Normalize MNIST input.\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "mnist_train = datasets.MNIST(os.path.expanduser(\n",
    "    \"~/.datasets\"), train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(os.path.expanduser(\n",
    "    \"~/.datasets\"), train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(train_loader))\n",
    "data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from ecoc.encode import read_codebook, get_codebook_tensor\n",
    "\n",
    "codebook_name = args[\"codebook_name\"]\n",
    "codebook_file = f\"../ecoc/codebooks/{codebook_name}.csv\"\n",
    "codebook = read_codebook(codebook_file)\n",
    "codebook_tensor = get_codebook_tensor(codebook).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [0., 1., 0., 1., 1.],\n",
       "        [0., 1., 1., 0., 1.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [1., 0., 0., 1., 1.],\n",
       "        [1., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 0.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [1., 1., 1., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [0., 1., 1., 0., 1.],\n",
       "        [1., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [1., 0., 1., 0., 1.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 1.],\n",
       "        [0., 1., 1., 0., 1.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 1., 0., 1., 1.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 1., 1., 0., 1.],\n",
       "        [1., 1., 0., 0., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 0.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [1., 0., 1., 0., 1.],\n",
       "        [1., 0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 1., 1., 1., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch ECOC encoding\n",
    "target_code = torch.zeros(len(data), 5).to(device)\n",
    "for i, c in enumerate(target):\n",
    "    target_code[i] += codebook_tensor[c]\n",
    "target_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_code = torch.sigmoid(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7461e-04, 9.9919e-01, 9.9995e-01, 5.3192e-05, 9.9999e-01],\n",
       "        [9.0802e-01, 9.7821e-01, 8.6991e-01, 7.3043e-02, 3.3803e-01],\n",
       "        [8.1087e-01, 9.9901e-01, 1.2846e-01, 3.0486e-02, 9.9635e-01],\n",
       "        [4.9451e-03, 9.9571e-01, 9.9864e-01, 2.9050e-01, 9.5692e-01],\n",
       "        [9.8374e-01, 1.7587e-03, 2.1061e-03, 9.9610e-01, 9.9981e-01],\n",
       "        [9.9938e-01, 9.9832e-01, 9.9981e-01, 1.5633e-03, 8.6092e-05],\n",
       "        [6.4486e-04, 1.7133e-05, 9.9998e-01, 9.9966e-01, 9.9958e-01],\n",
       "        [9.9966e-01, 9.7709e-01, 3.9838e-02, 8.1712e-03, 9.5563e-01],\n",
       "        [9.9955e-01, 5.3606e-04, 9.9902e-01, 5.0300e-04, 9.9970e-01],\n",
       "        [9.9998e-01, 9.8730e-01, 1.3803e-04, 9.9734e-01, 1.5907e-02],\n",
       "        [9.8861e-01, 9.9701e-01, 2.7495e-02, 9.4742e-01, 2.6049e-02],\n",
       "        [9.8513e-01, 5.6772e-02, 5.6491e-02, 9.7225e-01, 9.8223e-01],\n",
       "        [1.1108e-03, 9.9980e-01, 9.9864e-01, 2.2509e-02, 9.9026e-01],\n",
       "        [9.9988e-01, 9.9988e-01, 2.6610e-04, 9.6002e-05, 9.9978e-01],\n",
       "        [9.9122e-01, 9.9999e-01, 6.2346e-03, 5.3794e-03, 9.7375e-01],\n",
       "        [9.9989e-01, 9.9940e-01, 9.6525e-01, 1.1810e-02, 7.4882e-03],\n",
       "        [9.9773e-01, 9.9983e-01, 9.5789e-01, 1.5198e-03, 7.6825e-02],\n",
       "        [9.9994e-01, 9.9885e-01, 9.7684e-01, 2.9251e-02, 3.8155e-04],\n",
       "        [2.0010e-03, 9.9946e-01, 9.9974e-01, 9.8913e-01, 8.5211e-03],\n",
       "        [1.0170e-02, 9.9707e-01, 1.0289e-03, 9.8961e-01, 9.9979e-01],\n",
       "        [1.2863e-03, 9.9864e-01, 9.9998e-01, 9.8155e-01, 1.9183e-02],\n",
       "        [4.7153e-01, 4.2201e-02, 7.6374e-01, 9.9776e-01, 7.3636e-01],\n",
       "        [7.3468e-05, 1.0000e+00, 9.9994e-01, 1.8496e-05, 9.9999e-01],\n",
       "        [9.4728e-01, 9.9979e-01, 1.0013e-03, 4.0441e-01, 9.9743e-01],\n",
       "        [3.7879e-04, 3.8865e-04, 9.9988e-01, 9.9963e-01, 9.9927e-01],\n",
       "        [2.6611e-04, 1.0000e+00, 9.9902e-01, 9.9871e-01, 2.1421e-04],\n",
       "        [4.7250e-02, 4.4757e-03, 9.8154e-01, 9.9826e-01, 9.7209e-01],\n",
       "        [9.9998e-01, 4.0224e-03, 8.9529e-01, 1.2316e-03, 9.9950e-01],\n",
       "        [9.9957e-01, 1.7075e-02, 1.1229e-02, 9.8837e-01, 9.7522e-01],\n",
       "        [3.2097e-03, 9.9785e-01, 6.0635e-04, 9.9884e-01, 9.9962e-01],\n",
       "        [9.9975e-01, 9.9978e-01, 6.6898e-01, 7.6250e-04, 9.8116e-02],\n",
       "        [2.0693e-04, 1.0000e+00, 9.9986e-01, 9.8705e-01, 2.5034e-02]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss(reduction=\"none\")\n",
    "loss_mat = loss_fn(output_code, target_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def bce(a, b):\n",
    "    return -(b*math.log(a)+(1-b)*math.log(1-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9782, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(1., device='cuda:0')\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i, j = 1, 1\n",
    "print(output_code[i][j])\n",
    "print(target_code[i][j])\n",
    "print(loss_mat[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0220, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(bce(output_code[i][j], target_code[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.as_tensor((output_code - 0.5) > 0, dtype=torch.int32) \n",
    "\n",
    "distances = torch.zeros(len(result), len(codebook_tensor))\n",
    "for i, _result in enumerate(result):\n",
    "    for j, _code in enumerate(codebook_tensor):\n",
    "        distances[i][j] = (_result-_code).abs().sum()\n",
    "pred = distances.argmin(dim=1, keepdim=True).to(device)\n",
    "correct = pred.eq(target.view_as(pred)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 1], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 0., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook_tensor[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.l1_loss(result[0], codebook_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7288f315087fdb0a15835a979a50c8db3e0e21492381bafafe9d84f995bbb7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
